{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "In this notebook we will try out different classifiers. We will be using different versions of feature analysis to show which one is the best. Lastly we will compare the scores and the classifier with the highest scores will be used for the widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleCV import *\n",
    "# from IPython.display import HTML\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import matplotlib.cm as cm\n",
    "import sklearn \n",
    "# from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "# import cv2\n",
    "# import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# – Which steps did you take and which alternatives?\n",
    "# – What were the results of each of these steps and what was the\n",
    "# best option\n",
    "# – Which algorithm performs best with which hyperparameters\n",
    "# – Which labels get confused (confusion matrix)?\n",
    "# – What was your cross-validation strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_angle</th>\n",
       "      <th>blob_area</th>\n",
       "      <th>blob_centroid_x</th>\n",
       "      <th>blob_centroid_y</th>\n",
       "      <th>blob_width</th>\n",
       "      <th>centroid_bottom_is_empty</th>\n",
       "      <th>centroid_is_empty</th>\n",
       "      <th>centroid_top_is_empty</th>\n",
       "      <th>grid_2_0</th>\n",
       "      <th>grid_2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>grid_5_0</th>\n",
       "      <th>grid_5_1</th>\n",
       "      <th>grid_5_2</th>\n",
       "      <th>grid_5_3</th>\n",
       "      <th>grid_5_4</th>\n",
       "      <th>grid_5_5</th>\n",
       "      <th>grid_5_6</th>\n",
       "      <th>grid_5_7</th>\n",
       "      <th>number_of_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.386221</td>\n",
       "      <td>0.469217</td>\n",
       "      <td>0.467661</td>\n",
       "      <td>0.522865</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.295312</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.393815</td>\n",
       "      <td>0.665495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379785</td>\n",
       "      <td>0.533919</td>\n",
       "      <td>0.516829</td>\n",
       "      <td>0.510319</td>\n",
       "      <td>0.586458</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.591960</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.368169</td>\n",
       "      <td>0.187824</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.101772</td>\n",
       "      <td>0.476765</td>\n",
       "      <td>0.456302</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>0.342701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383374</td>\n",
       "      <td>0.376778</td>\n",
       "      <td>0.400050</td>\n",
       "      <td>0.382840</td>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>0.403487</td>\n",
       "      <td>0.287165</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.863493</td>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>0.344453</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.973220</td>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.459344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481894</td>\n",
       "      <td>0.552328</td>\n",
       "      <td>0.562653</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        blob_angle    blob_area  blob_centroid_x  blob_centroid_y  \\\n",
       "count  1920.000000  1920.000000      1920.000000      1920.000000   \n",
       "mean      0.779948     0.386221         0.469217         0.467661   \n",
       "std       0.368169     0.187824         0.139196         0.182193   \n",
       "min       0.000000     0.000000         0.000000         0.000000   \n",
       "25%       0.863493     0.253482         0.378048         0.344453   \n",
       "50%       0.973220     0.341226         0.462067         0.459344   \n",
       "75%       1.000000     0.481894         0.552328         0.562653   \n",
       "max       1.000000     1.000000         1.000000         1.000000   \n",
       "\n",
       "        blob_width  centroid_bottom_is_empty  centroid_is_empty  \\\n",
       "count  1920.000000               1920.000000        1920.000000   \n",
       "mean      0.522865                  0.348958           0.295312   \n",
       "std       0.101772                  0.476765           0.456302   \n",
       "min       0.000000                  0.000000           0.000000   \n",
       "25%       0.500000                  0.000000           0.000000   \n",
       "50%       0.500000                  0.000000           0.000000   \n",
       "75%       0.600000                  1.000000           1.000000   \n",
       "max       1.000000                  1.000000           1.000000   \n",
       "\n",
       "       centroid_top_is_empty     grid_2_0     grid_2_1     ...       \\\n",
       "count            1920.000000  1920.000000  1920.000000     ...        \n",
       "mean                0.211458     0.393815     0.665495     ...        \n",
       "std                 0.408449     0.333569     0.342701     ...        \n",
       "min                 0.000000     0.000000     0.000000     ...        \n",
       "25%                 0.000000     0.062500     0.437500     ...        \n",
       "50%                 0.000000     0.375000     0.812500     ...        \n",
       "75%                 0.000000     0.687500     1.000000     ...        \n",
       "max                 1.000000     1.000000     1.000000     ...        \n",
       "\n",
       "          grid_5_0     grid_5_1     grid_5_2     grid_5_3     grid_5_4  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.379785     0.533919     0.516829     0.510319     0.586458   \n",
       "std       0.383374     0.376778     0.400050     0.382840     0.370961   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.125000     0.000000     0.125000     0.250000   \n",
       "50%       0.250000     0.562500     0.562500     0.500000     0.687500   \n",
       "75%       0.750000     0.937500     0.937500     0.875000     0.937500   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          grid_5_5     grid_5_6     grid_5_7  number_of_holes        label  \n",
       "count  1920.000000  1920.000000  1920.000000      1920.000000  1920.000000  \n",
       "mean      0.551400     0.591960     0.472656         0.188542     4.532813  \n",
       "std       0.369417     0.375565     0.403487         0.287165     2.868122  \n",
       "min       0.000000     0.000000     0.000000         0.000000     0.000000  \n",
       "25%       0.187500     0.250000     0.000000         0.000000     2.000000  \n",
       "50%       0.625000     0.750000     0.437500         0.000000     5.000000  \n",
       "75%       0.875000     0.937500     0.875000         0.500000     7.000000  \n",
       "max       1.000000     1.000000     1.000000         1.000000     9.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"../dataset-numpy/dataset_analysis.csv\")\n",
    "# wordt niet hoger door normalizen\n",
    "df = pd.read_csv(\"../dataset-numpy/dataset_analysis_normalized_v3.csv\")\n",
    "df.head()\n",
    "\n",
    "# split df in data (X) and labels (y)\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# create train and test data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20, random_state=67)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "PCA stands for pricipal components analysis. With PCA the dimensions of data is reduced, it is summarized. In our case we took 0.95 procent of the components. When testing our classifiers with the PSA dataset some classifiers decreased in score and some increased. We made the choice to only use de PSA datasets where the score increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "We chose two naive bays models. Gaussian which can be used if a dataset has a normal distribution. Bernoulli which works better if the features are with zeros and ones. The outputs of these classifiers where rather low it would not reach the level of other classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian : 0.94270833333333337\n",
    "Gaussian worked better with the PCA dataset. For this classifier there was a lot of confusion placing the number 1 with the correct label, the classifier misplaced it 7 times. As a 2,3,4 and for a 8 and 9.  The number 9 was confused 9 times. As a 4,5 and 8. The numbers 5 and 6 where the only number that are not confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942708333333\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  0  0  0  1  1  2  4]\n",
      " [ 0  0 33  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  1  0  0  0  1]\n",
      " [ 0  0  0  0 28  0  1  2  0  0]\n",
      " [ 0  0  0  0  0 24  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 32  1]\n",
      " [ 0  0  1  0  1  4  0  0  0 47]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Gaussian\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_pca, y_train)\n",
    "#print \"Gaussian :\",gnb.score(X_test_pca, y_test)\n",
    "prediction=gnb.predict(X_test_pca)\n",
    "accuracy_score_gnb = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_gnb \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli: 0.84895833333333337\n",
    "We also tried to use the Bernoulli classifier. This classifier scored rather low. This is because our dataset does not only consist out of zeros and ones but also out of other numbers. When looking at the confusion matrix every number has been confused for other numbers except 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Bernoulli:', 0.86979166666666663)\n",
      "[[42  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 30  0  1  6  0  1  0  0  2]\n",
      " [ 0  4 30  2  0  0  0  0  0  0]\n",
      " [ 0  0  0 32  0  0  0  0  1  1]\n",
      " [ 0  1  0  0 22  0  0  2  0  4]\n",
      " [ 0  1  1  2  0 23  0  0  1  0]\n",
      " [ 0  0  1  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 49  1  1]\n",
      " [ 0  3  1  1  0  1  0  0 32  2]\n",
      " [ 0  0  1  2  0  4  0  0  0 43]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Bernoulli\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "#print \"Bernoulli:\",bnb.score(X_test, y_test)\n",
    "prediction=bnb.predict(X_test)\n",
    "accuracy_score_bnb = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_bnb\n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRF = RandomForestClassifier()\n",
    "clfRF.fit(X_train, y_train)\n",
    "prediction=clfRF.predict(X_test)\n",
    "\n",
    "accuracy_score_rf = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_rf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomize search\n",
    "When running random forest with default settings the score was about 0.945. The descision was made to tune the hyper parameters. To get the best possible parameters we used the randomized search in combination with the grid search. This tries all the combinations between a certain range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trees \n",
    "n_estimators=[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] \n",
    "\n",
    "#number of features considered for splitting at leaf node\n",
    "max_features =['sqrt', 'auto']\n",
    "\n",
    "#method for sampling data points (with or without replacement)\n",
    "bootstrap=[True, False]\n",
    "\n",
    "#min number of data points allowed in a leaf node\n",
    "min_samples_leaf=[1,2,4]\n",
    "\n",
    "#min number of data points placed in a node before the node is split\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "#max number of levels in each decision tree\n",
    "max_depth=[int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "randomgrid = {'n_estimators':n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'bootstrap': bootstrap,\n",
    "             'min_samples_leaf': min_samples_leaf,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'max_depth': max_depth}\n",
    "\n",
    "clfRF = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clfRF, param_distributions = randomgrid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The best params that came out of the randomize search:\n",
    "  bootstrap: False\n",
    "  <br>\n",
    "  max_depth: 20\n",
    "  <br>\n",
    "  max_features: 'sqrt'\n",
    "  <br>\n",
    "  min_samples_leaf: 1\n",
    "  <br>\n",
    "  min_samples_split: 2\n",
    "  <br>\n",
    "  n_estimators: 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "To get even better hyper parameters, we are using the result of the randomize search to narrow down the range for the grid search. There is a change that this score could be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [10,20,30,40,50],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'n_estimators': [1400,1500,1600,1800,1900,2000]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "clfRF = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = clfRF, param_grid = parameters, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The best params that came out of the grid search\n",
    "bootstrap: False\n",
    "<br>\n",
    "max_depth: 40\n",
    "<br>\n",
    "max_features: 'sqrt'\n",
    "<br>\n",
    "min_samples_leaf: 1\n",
    "<br>\n",
    "min_samples_split: 2\n",
    "<br>\n",
    "n_estimators: 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default setting of the random forest the acurracy score was about 0.945. Running the random forest with the tuned parameters the accurracy score came to 0.97916666666666663. This is an increase of about 3%. When looking at the confusion matrix number 1 catches our attention. Number 1 was mismatched to a 2, 8 and 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest with parameters from random and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.98177083333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 34  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 27  1  0  0  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 51  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 35  1]\n",
      " [ 0  0  0  0  0  2  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(bootstrap= False,  max_depth= 40, max_features= 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 1600)\n",
    "clfRF.fit(X_train, y_train)\n",
    "prediction=clfRF.predict(X_test)\n",
    "\n",
    "accuracy_score_rf = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy :\",accuracy_score_rf \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test) \n",
    "print metrics.classification_report(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree\n",
    "The decision tree scored with default settings only  0.86979166666666663. Tuning parameters will not get this classifier to the accurracy scores of other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.875)\n",
      "[[34  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 37  8  1  3  0  1  0  2  1]\n",
      " [ 0  1 32  2  0  1  0  0  0  1]\n",
      " [ 1  0  1 33  1  2  0  0  0  0]\n",
      " [ 0  1  1  0 41  0  0  0  2  2]\n",
      " [ 0  0  1  0  0 25  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 36  0  2  0]\n",
      " [ 0  0  0  2  0  0  0 37  0  2]\n",
      " [ 0  1  0  1  1  0  1  0 32  1]\n",
      " [ 0  0  0  0  0  0  0  2  0 29]]\n"
     ]
    }
   ],
   "source": [
    "clfDT = DecisionTreeClassifier()\n",
    "clfDT.fit(X_train, y_train) \n",
    "prediction=clfDT.predict(X_test)\n",
    "\n",
    "accuracy_score_dt = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",accuracy_score_dt)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfKNN = KNeighborsClassifier()\n",
    "# Train the classifier with the training data and training labels\n",
    "clfKNN.fit(X_train, y_train)\n",
    "    # Score the classifier\n",
    "    # (calculates the mean accuracy of the given test data) \n",
    "prediction=clfKNN.predict(X_test)\n",
    "print \"Accuracy: \", metrics.accuracy_score(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the KNN we first let it run with default settings. The accurracy score was already near the 0.97135416666666663 . So we decided to try to make this higher with tuning the hyper parameters. We first ran the classifier with an iteration. Where it would try the neighbors 1-9 in the params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    # Create a classifier with k \n",
    "    clfKNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    # Train the classifier with the training data and training labels\n",
    "    clfKNN.fit(X_train, y_train)\n",
    "    # Score the classifier\n",
    "    # (calculates the mean accuracy of the given test data) \n",
    "    prediction=clfKNN.predict(X_test)\n",
    "    print \"Accuracy: \", i ,metrics.accuracy_score(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN with neighbor iteration\n",
    "Accuracy: 0.96354166666666663 Neighbors: 1\n",
    "<br>\n",
    "Accuracy: 0.96354166666666663 Neighbors: 2\n",
    "<br>\n",
    "Accuracy: 0.97135416666666663 Neighbors: 3\n",
    "<br>\n",
    "Accuracy: 0.96875........................ Neighbors: 4\n",
    "<br>\n",
    "Accuracy: 0.97135416666666663 Neighbors: 5\n",
    "<br>\n",
    "Accuracy: 0.96614583333333337 Neighbors: 6\n",
    "<br>\n",
    "Accuracy: 0.96354166666666663 Neighbors: 7\n",
    "<br>\n",
    "Accuracy: 0.96614583333333337 Neighbors: 8\n",
    "<br>\n",
    "Accuracy: 0.96614583333333337 Neighbors: 9\n",
    "<br>\n",
    "<br>\n",
    "The highest accurracy score of running the classifier with an iterator is the same as when running it default 0.97135416666666663. As the iteration only focuced on the neighbors we decided to use grid search. We know tuned more than one parameter.\n",
    "<br>\n",
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the instance\n",
    "clfKNN = KNeighborsClassifier(n_jobs=-1)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "clfKNN1 = GridSearchCV(clfKNN, param_grid=params, n_jobs=-1, verbose=1)\n",
    "#Learning\n",
    "clfKNN1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best params for KNN with grid search\n",
    "algorithm': 'auto'\n",
    "<br>\n",
    "leaf_size': 1\n",
    "<br>\n",
    "n_jobs': -1\n",
    "<br>\n",
    "n_neighbors': 6\n",
    "<br>\n",
    "weights': 'distance'\n",
    "<br>\n",
    "<br>\n",
    "Running the classifier with the params from the gridsearch improved the accurracy score. It is now 0.97395833333333337. It is an improvement of about 0.20%. When looking at the confusion matrix number 1 stands out. Number 1 is misplaced for number 2,3,4,8 and 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.97395833333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  1  1  1  0  0  0  1  1]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 27  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 51  0  1]\n",
      " [ 0  0  0  0  1  0  0  0 34  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "clfKNN = KNeighborsClassifier(n_neighbors = 6, n_jobs = -1, weights= 'distance', leaf_size= 1, algorithm= 'auto')\n",
    "clfKNN.fit(X_train, y_train)\n",
    "prediction=clfKNN.predict(X_test)\n",
    "\n",
    "accuracy_score_knn = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_knn \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.96614583333333337)\n",
      "[[41  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  0  0  0  0  1  0  0  1]\n",
      " [ 0  0 34  0  0  2  0  0  0  1]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  0  0  2]\n",
      " [ 1  0  0  0  0 26  1  0  1  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 51  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 34  1]\n",
      " [ 0  0  0  0  0  1  0  0  0 48]]\n"
     ]
    }
   ],
   "source": [
    "clfSGD = linear_model.SGDClassifier(loss = 'log', n_iter =1000)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "prediction=clfSGD.predict(X_test)\n",
    "\n",
    "accuracy_score_sgd = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy Gaussian:\",accuracy_score_sgd \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test) \n",
    "#Without PCA\n",
    "#0.95833333333333337\n",
    "#With PCA\n",
    "#0.0.95833333333333337\n",
    "\n",
    "#default = 0.934895833333\n",
    "#n_iter =1000 = 0.919270833333\n",
    "#loss = 'log', n_iter =1000 = 0.934895833333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979166666667\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1520 candidates, totalling 7600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6388 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7600 out of 7600 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 1.2000000000000002, 'gamma': 0.17100000000000001}\n",
      "0.981119791667\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(0.1, 2, 0.1), \n",
    "              'gamma': np.arange(.001, .2, 0.005)}\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(), parameters, verbose=1, n_jobs=-1, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print clf.best_params_\n",
    "print clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best params for SVM with grid search\n",
    "kernel': 'rbf'\n",
    "<br>\n",
    "C': 1.2\n",
    "<br>\n",
    "gamma': 0.171\n",
    "\n",
    "will score 0.9811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978489583333\n",
      "0.955729166667\n",
      "0.997395833333\n"
     ]
    }
   ],
   "source": [
    "# 0.979166666667 met pca en normalized zonder contours\n",
    "# 0.984375 zonder pca, normalized, zonder contours \n",
    "\n",
    "# 0.979609375\n",
    "# 0.9609375\n",
    "# 0.9921875\n",
    "scores = np.zeros((100))\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20)\n",
    "    clf = svm.SVC(kernel =\"rbf\", C=1.2, gamma=0.171)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores[i] = clf.score(X_test, y_test)\n",
    "\n",
    "print scores.mean()\n",
    "    \n",
    "print scores.min()\n",
    "print scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979166666667\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel =\"rbf\", C=1.2, gamma=0.171)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 41  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 36  0  2  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 37  0  0  0  0]\n",
      " [ 0  0  0  0  0  1 37  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 38  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 37  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 48]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        34\n",
      "          1       0.95      1.00      0.98        41\n",
      "          2       1.00      1.00      1.00        41\n",
      "          3       0.97      0.95      0.96        38\n",
      "          4       1.00      0.97      0.98        29\n",
      "          5       0.93      1.00      0.96        37\n",
      "          6       0.97      0.97      0.97        38\n",
      "          7       1.00      0.97      0.99        39\n",
      "          8       1.00      0.95      0.97        39\n",
      "          9       0.98      1.00      0.99        48\n",
      "\n",
      "avg / total       0.98      0.98      0.98       384\n",
      "\n",
      "0.979166666667\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "print confusion_matrix (labels, predictions)\n",
    "print classification_report(labels, predictions)\n",
    "print metrics.accuracy_score(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98177083333333337"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.5s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.4s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.5s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.6s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.6s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.5s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.3s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.4s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.4s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.3s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.4s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.3s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.4s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.4s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.3s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.3s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.4s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.4s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.4s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.4s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters:\\n', {'logreg__C': 10.01})\n",
      "('Score:\\n', 0.95768229166666663)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "parameters = {'logreg__C':np.arange(0.01,100,10)}\n",
    "clfLG = GridSearchCV(pipeline,parameters,cv=5, n_jobs=-1, verbose =2)\n",
    "clfLG.fit(X_train, y_train)\n",
    "print(\"Best parameters:\\n\",clfLG.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.9765625)\n",
      "[[32  0  0  0  0  0  0  0  0  1]\n",
      " [ 0 39  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 38  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 33  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 41  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 33  0  0  1  0]\n",
      " [ 0  0  0  0  1  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 41  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 39  1]\n",
      " [ 0  0  0  1  0  0  0  0  0 35]]\n"
     ]
    }
   ],
   "source": [
    "clfLG = LogisticRegression(random_state=0, solver='lbfgs',  multi_class='multinomial', C =10.01 )\n",
    "clfLG.fit(X_train, y_train)\n",
    "prediction=clfLG.predict(X_test)\n",
    "accuracy_score_lg = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy Gaussian:\",accuracy_score_lg \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)\n",
    "#With PCA\n",
    "#0.94791666666666663\n",
    "#Without\n",
    "#0.95572916666666663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gaussian               94.270833\n",
       "Bernoulli              84.895833\n",
       "Random Forest          97.656250\n",
       "Decision Tree          86.979167\n",
       "KNN                    97.395833\n",
       "SGD                    95.833333\n",
       "SVM                    98.096354\n",
       "Logestic Regression    95.572917\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_svm = scores.mean()\n",
    "dfResults = pd.Series([accuracy_score_gnb*100, accuracy_score_bnb*100,accuracy_score_rf*100, accuracy_score_dt*100,\n",
    "                       accuracy_score_knn*100, accuracy_score_sgd*100, accuracy_score_svm*100, accuracy_score_lg*100],\n",
    "                      index=['Gaussian', 'Bernoulli', 'Random Forest', 'Decision Tree',\n",
    "                             'KNN', 'SGD','SVM', 'Logestic Regression'])\n",
    "dfResults.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svcModel.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "clf = svm.SVC(kernel= 'rbf', C= 1.9, gamma= 0.161)\n",
    "\n",
    "clf.fit(X, y)\n",
    "# Save the classifier in a file\n",
    "joblib.dump(clf, 'svcModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1.4000000000000004, 'svm__kernel': 'rbf', 'svm__gamma': 0.20000000000000001}\n",
      "0.977864583333\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # {'pca__n_components': 24, 'svm__C': 2.1, 'svm__kernel': 'rbf', 'svm__gamma': 0.20000000000000004}\n",
    "# # 0.977213541667\n",
    "\n",
    "# pipeline = Pipeline([('pca', PCA()), ('svm', svm.SVC())])\n",
    "# parameter_grid = {\n",
    "# #     'pca__n_components' : range(1,24),\n",
    "#     'svm__kernel' : ['linear', 'rbf'],\n",
    "#     'svm__C' : np.arange(1, 5, 0.1),\n",
    "#     'svm__gamma': np.arange(.1, 1, .1)\n",
    "# }\n",
    "# # parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(1,100), 'gamma': np.arange(.1, 1, 0.05)}\n",
    "\n",
    "# # svc = svm.SVC(gamma = j)\n",
    "# # print j\n",
    "# # n_jobs-1 = aantal cores/multithreading\n",
    "# # verbose print spul\n",
    "# clf = GridSearchCV(pipeline, parameter_grid, verbose=1, n_jobs=-1, cv = 5)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print clf.best_params_\n",
    "# print clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 1, 'gamma': 0}\n",
      "0.963541666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.4s finished\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

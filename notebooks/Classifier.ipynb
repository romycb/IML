{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meer grid based dingen toevoegen, nu gaan we niet hoger komen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleCV import *\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import sklearn \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_area</th>\n",
       "      <th>blob_centroid_x</th>\n",
       "      <th>blob_centroid_y</th>\n",
       "      <th>blob_angle</th>\n",
       "      <th>blob_width</th>\n",
       "      <th>number_of_holes</th>\n",
       "      <th>centroid_is_empty</th>\n",
       "      <th>centroid_top_is_empty</th>\n",
       "      <th>centroid_bottom_is_empty</th>\n",
       "      <th>grid_2_0</th>\n",
       "      <th>...</th>\n",
       "      <th>grid_4_7</th>\n",
       "      <th>grid_5_0</th>\n",
       "      <th>grid_5_1</th>\n",
       "      <th>grid_5_2</th>\n",
       "      <th>grid_5_3</th>\n",
       "      <th>grid_5_4</th>\n",
       "      <th>grid_5_5</th>\n",
       "      <th>grid_5_6</th>\n",
       "      <th>grid_5_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.386221</td>\n",
       "      <td>0.469217</td>\n",
       "      <td>0.467661</td>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.522865</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>0.295312</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.393815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781217</td>\n",
       "      <td>0.379785</td>\n",
       "      <td>0.533919</td>\n",
       "      <td>0.516829</td>\n",
       "      <td>0.510319</td>\n",
       "      <td>0.586458</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.591960</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187824</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.368169</td>\n",
       "      <td>0.101772</td>\n",
       "      <td>0.287165</td>\n",
       "      <td>0.456302</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.476765</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331414</td>\n",
       "      <td>0.383374</td>\n",
       "      <td>0.376778</td>\n",
       "      <td>0.400050</td>\n",
       "      <td>0.382840</td>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>0.403487</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>0.344453</td>\n",
       "      <td>0.863493</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.459344</td>\n",
       "      <td>0.973220</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.481894</td>\n",
       "      <td>0.552328</td>\n",
       "      <td>0.562653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         blob_area  blob_centroid_x  blob_centroid_y   blob_angle  \\\n",
       "count  1920.000000      1920.000000      1920.000000  1920.000000   \n",
       "mean      0.386221         0.469217         0.467661     0.779948   \n",
       "std       0.187824         0.139196         0.182193     0.368169   \n",
       "min       0.000000         0.000000         0.000000     0.000000   \n",
       "25%       0.253482         0.378048         0.344453     0.863493   \n",
       "50%       0.341226         0.462067         0.459344     0.973220   \n",
       "75%       0.481894         0.552328         0.562653     1.000000   \n",
       "max       1.000000         1.000000         1.000000     1.000000   \n",
       "\n",
       "        blob_width  number_of_holes  centroid_is_empty  centroid_top_is_empty  \\\n",
       "count  1920.000000      1920.000000        1920.000000            1920.000000   \n",
       "mean      0.522865         0.188542           0.295312               0.211458   \n",
       "std       0.101772         0.287165           0.456302               0.408449   \n",
       "min       0.000000         0.000000           0.000000               0.000000   \n",
       "25%       0.500000         0.000000           0.000000               0.000000   \n",
       "50%       0.500000         0.000000           0.000000               0.000000   \n",
       "75%       0.600000         0.500000           1.000000               0.000000   \n",
       "max       1.000000         1.000000           1.000000               1.000000   \n",
       "\n",
       "       centroid_bottom_is_empty     grid_2_0     ...          grid_4_7  \\\n",
       "count               1920.000000  1920.000000     ...       1920.000000   \n",
       "mean                   0.348958     0.393815     ...          0.781217   \n",
       "std                    0.476765     0.333569     ...          0.331414   \n",
       "min                    0.000000     0.000000     ...          0.000000   \n",
       "25%                    0.000000     0.062500     ...          0.625000   \n",
       "50%                    0.000000     0.375000     ...          1.000000   \n",
       "75%                    1.000000     0.687500     ...          1.000000   \n",
       "max                    1.000000     1.000000     ...          1.000000   \n",
       "\n",
       "          grid_5_0     grid_5_1     grid_5_2     grid_5_3     grid_5_4  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.379785     0.533919     0.516829     0.510319     0.586458   \n",
       "std       0.383374     0.376778     0.400050     0.382840     0.370961   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.125000     0.000000     0.125000     0.250000   \n",
       "50%       0.250000     0.562500     0.562500     0.500000     0.687500   \n",
       "75%       0.750000     0.937500     0.937500     0.875000     0.937500   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          grid_5_5     grid_5_6     grid_5_7        label  \n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  \n",
       "mean      0.551400     0.591960     0.472656     4.532813  \n",
       "std       0.369417     0.375565     0.403487     2.868122  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.187500     0.250000     0.000000     2.000000  \n",
       "50%       0.625000     0.750000     0.437500     5.000000  \n",
       "75%       0.875000     0.937500     0.875000     7.000000  \n",
       "max       1.000000     1.000000     1.000000     9.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"../dataset-numpy/dataset_analysis.csv\")\n",
    "# wordt niet hoger door normalizen\n",
    "df = pd.read_csv(\"../dataset-numpy/dataset_analysis_normalized.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "# split df in data (X) and labels (y)\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# create train and test data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20, random_state=42)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler() # Scale the training features\n",
    "# training_set = min_max_scaler.fit_transform(X_train)\n",
    "# # Scale the test features (using the same settings as the trainingset)\n",
    "# test_set = min_max_scaler.transform(X_test)\n",
    "# print test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train)\n",
    "pca.n_components_\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian : 0.921875\n",
      "Bernoulli: 0.770833333333\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Gaussian\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "#y_pred = gnb.predict(X_test)\n",
    "print \"Gaussian :\",gnb.score(X_test, y_test)\n",
    "\n",
    "#Naive Bayes Bernoulli\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "#y_pred = gnb.predict(X_test)\n",
    "print \"Bernoulli:\",bnb.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest randomize search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] bootstrap=True, min_samples_leaf=1, n_estimators=400, min_samples_split=5, max_features=auto, max_depth=30 \n",
      "[CV] bootstrap=True, min_samples_leaf=1, n_estimators=400, min_samples_split=5, max_features=auto, max_depth=30 \n",
      "[CV] bootstrap=True, min_samples_leaf=1, n_estimators=400, min_samples_split=5, max_features=auto, max_depth=30 \n",
      "[CV] bootstrap=True, min_samples_leaf=1, n_estimators=2000, min_samples_split=5, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-25a2e8f18a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Fit the random search model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#number of trees \n",
    "n_estimators=[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] \n",
    "\n",
    "#number of features considered for splitting at leaf node\n",
    "max_features =['sqrt', 'auto']\n",
    "\n",
    "#method for sampling data points (with or without replacement)\n",
    "bootstrap=[True, False]\n",
    "\n",
    "#min number of data points allowed in a leaf node\n",
    "min_samples_leaf=[1,2,4]\n",
    "\n",
    "#min number of data points placed in a node before the node is split\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "#max number of levels in each decision tree\n",
    "max_depth=[int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "randomgrid = {'n_estimators':n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'bootstrap': bootstrap,\n",
    "             'min_samples_leaf': min_samples_leaf,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'max_depth': max_depth}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = randomgrid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_\n",
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [30,40,50,60,70],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1,2,4],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'n_estimators': [800,900,1000,1100,1200,1300,1400]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: 0.9140625\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "# Create a random forest classifier\n",
    "clfRF = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "# Train the classifier to take the training features and learn how they relate to the training y\n",
    "clfRF.fit(X_train, y_train)\n",
    "print \"Random forest:\",clfRF.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: 0.947916666667\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'min_impurity_decrease': 0.0, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 900, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'min_impurity_split': None, 'max_features': 'sqrt', 'max_depth': 40, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "#randomize search outcome Random forest: 0.966145833333\n",
    "# clfRF = RandomForestClassifier(bootstrap= False,  max_depth= 50, max_features= 'sqrt',\n",
    "#                                min_samples_leaf = 1, min_samples_split = 2, n_estimators = 1000)\n",
    "#grid search outcome:  0.96875\n",
    "clfRF = RandomForestClassifier(bootstrap= False,  max_depth= 40, max_features= 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 900)\n",
    "\n",
    "clfRF.fit(X_train, y_train)\n",
    "print \"Random forest:\",clfRF.score(X_test, y_test)\n",
    "print(clfRF.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.8203125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Decision tree  0.8671875\n",
    "clfDT = DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_features = None, max_depth = 52)\n",
    "clfDT.fit(X_train, y_train) \n",
    "print \"Decision tree:\",clfDT.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  1.1min\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters:\\n', {'n_neighbors': 5, 'n_jobs': -1, 'weights': 'distance', 'leaf_size': 1, 'algorithm': 'auto'})\n",
      "('Accuracy:', 0.96875)\n",
      "[[31  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 47  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 41  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  0  0  1  1]\n",
      " [ 0  0  0  1  0 31  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 39  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 44  0  2]\n",
      " [ 0  0  0  0  0  0  0  0 36  0]\n",
      " [ 0  0  0  0  3  0  0  0  0 33]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "#making the instance\n",
    "clfKNN = KNeighborsClassifier(n_jobs=-1)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "clfKNN1 = GridSearchCV(clfKNN, param_grid=params, n_jobs=-1, verbose=1)\n",
    "#Learning\n",
    "clfKNN1.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best parameters:\\n\",clfKNN1.best_params_)\n",
    "#Prediction\n",
    "prediction=clfKNN1.predict(X_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973958333333\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# niet accurate, hoeveelheid neighbors:\n",
    "# Score KNN:  1 0.971354166667\n",
    "# Score KNN:  2 0.9609375\n",
    "# Score KNN:  3 0.963541666667\n",
    "# Score KNN:  4 0.966145833333\n",
    "# Score KNN:  5 0.963541666667\n",
    "# Score KNN:  6 0.963541666667\n",
    "# Score KNN:  7 0.963541666667\n",
    "# Score KNN:  8 0.9609375\n",
    "# Score KNN:  9 0.963541666667\n",
    "\n",
    "\n",
    "\n",
    "clfKNN = KNeighborsClassifier(n_neighbors = 4, n_jobs = -1, weights= 'distance', leaf_size= 1, algorithm= 'auto')\n",
    "# for i in range (1,10):\n",
    "#     # Create a classifier with k \n",
    "#     clfKNN = KNeighborsClassifier(n_neighbors=i)\n",
    "#     # Train the classifier with the training data and training labels\n",
    "#     clfKNN.fit(X_train, y_train)\n",
    "\n",
    "#     # Score the classifier\n",
    "#     # (calculates the mean accuracy of the given test data) \n",
    "#     score = clfKNN.score(test_set, y_test)\n",
    "#     print \"Score KNN: \", i , score\n",
    "clfKNN.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "# (calculates the mean accuracy of the given test data) \n",
    "score = clfKNN.score(X_test, y_test)\n",
    "print score\n",
    "# print \"Score KNN: \", i , score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'average': False,\n",
       " 'class_weight': None,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.15,\n",
       " 'learning_rate': 'optimal',\n",
       " 'loss': 'hinge',\n",
       " 'max_iter': None,\n",
       " 'n_iter': None,\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'tol': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.get_params()\n",
    "# params = { 'loss': ['log'],\n",
    "#         'penalty': ['elasticnet'],\n",
    "#         'alpha': [10 ** x for x in range(-6, 1)],\n",
    "#     'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "#           'n_jobs':[-1]}\n",
    "                            \n",
    "# clf1 = GridSearchCV(clf, param_grid=params, n_jobs=-1, verbose=1)\n",
    "# #Learning\n",
    "# clf1.fit(training_set,y_train)\n",
    "# #The best hyper parameters set\n",
    "# print(\"Best Hyper Parameters:\\n\",clf1.best_params_)\n",
    "# #Prediction\n",
    "# prediction=clf1.predict(test_set)\n",
    "# #importing the metrics module\n",
    "# from sklearn import metrics\n",
    "# #evaluation(Accuracy)\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "# #evaluation(Confusion Metrix)\n",
    "# print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1520 candidates, totalling 7600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6388 tasks      | elapsed:  5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 1.9000000000000001, 'gamma': 0.19600000000000001}\n",
      "0.977213541667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 7600 out of 7600 | elapsed:  5.9min finished\n"
     ]
    }
   ],
   "source": [
    "# {'kernel': 'rbf', 'C': 1.9000000000000001, 'gamma': 0.161}\n",
    "# 0.978515625\n",
    "\n",
    "# {'kernel': 'rbf', 'C': 1.9000000000000001, 'gamma': 0.19600000000000001}\n",
    "# 0.977213541667\n",
    "\n",
    "parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(0.1, 2, 0.1), \n",
    "              'gamma': np.arange(.001, .2, 0.005)}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(), parameters, verbose=1, n_jobs=-1, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print clf.best_params_\n",
    "print clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979166666667\n"
     ]
    }
   ],
   "source": [
    "# 0.979166666667 met pca en normalized zonder contours\n",
    "\n",
    "clf = svm.SVC(kernel =\"rbf\", C=1.9, gamma=0.161)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 47  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 40  0  2  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  0  0  0  3]\n",
      " [ 0  0  0  0  0 32  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 39  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 44  0  0]\n",
      " [ 0  0  0  0  0  1  0  0 39  0]\n",
      " [ 0  0  0  0  1  0  0  1  0 34]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        47\n",
      "          2       1.00      1.00      1.00        42\n",
      "          3       1.00      0.95      0.98        42\n",
      "          4       0.97      0.90      0.93        31\n",
      "          5       0.91      1.00      0.96        32\n",
      "          6       1.00      1.00      1.00        39\n",
      "          7       0.98      1.00      0.99        44\n",
      "          8       1.00      0.97      0.99        40\n",
      "          9       0.92      0.94      0.93        36\n",
      "\n",
      "avg / total       0.98      0.98      0.98       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "print confusion_matrix (labels, predictions)\n",
    "print classification_report(labels, predictions)\n",
    "\n",
    "# for p, l in zip(predictions, labels):\n",
    "#     print p, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98177083333333337"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.1s\n",
      "[CV] ................................... logreg__C=0.01, total=   0.1s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.0s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.1s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.1s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   0.2s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   0.1s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   0.1s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   0.1s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   0.1s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   0.2s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   0.1s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   0.2s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   0.2s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   0.2s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   0.2s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   0.2s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   0.2s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   0.2s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   0.2s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   0.2s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   0.2s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   0.2s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   0.2s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   0.2s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   0.2s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   0.2s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   0.2s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   0.2s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   0.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   0.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] logreg__C=60.01 .................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3e182bb83d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'logreg__C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclfLG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclfLG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclfLG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Score:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfLG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "parameters = {'logreg__C':np.arange(0.01,100,10)}\n",
    "clfLG = GridSearchCV(pipeline,parameters,cv=5, n_jobs=-1, verbose =2)\n",
    "clfLG.fit(X_train, y_train)\n",
    "print(\"Best parameters:\\n\",clfLG.best_params_)\n",
    "print (\"Score:\\n\", clfLG.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947916666667\n"
     ]
    }
   ],
   "source": [
    "clfLG = LogisticRegression(random_state=0, solver='lbfgs',  multi_class='multinomial', C =10.01 )\n",
    "clfLG.fit(X_train, y_train)\n",
    "print clfLG.score(X_test, y_test)\n",
    "#0.947916666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934895833333\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDClassifier(loss = 'log', n_iter =1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print clf.score(X_test, y_test)\n",
    "\n",
    "#default = 0.934895833333\n",
    "#n_iter =1000 = 0.919270833333\n",
    "#loss = 'log', n_iter =1000 = 0.934895833333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "clf = svm.SVC(kernel= 'rbf', C= 1.9, gamma= 0.161) \n",
    "clf.fit(X_train, y_train)\n",
    "# Save the classifier in a file\n",
    "joblib.dump(clf, 'svcModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1.4000000000000004, 'svm__kernel': 'rbf', 'svm__gamma': 0.20000000000000001}\n",
      "0.977864583333\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # {'pca__n_components': 24, 'svm__C': 2.1, 'svm__kernel': 'rbf', 'svm__gamma': 0.20000000000000004}\n",
    "# # 0.977213541667\n",
    "\n",
    "# pipeline = Pipeline([('pca', PCA()), ('svm', svm.SVC())])\n",
    "# parameter_grid = {\n",
    "# #     'pca__n_components' : range(1,24),\n",
    "#     'svm__kernel' : ['linear', 'rbf'],\n",
    "#     'svm__C' : np.arange(1, 5, 0.1),\n",
    "#     'svm__gamma': np.arange(.1, 1, .1)\n",
    "# }\n",
    "# # parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(1,100), 'gamma': np.arange(.1, 1, 0.05)}\n",
    "\n",
    "# # svc = svm.SVC(gamma = j)\n",
    "# # print j\n",
    "# # n_jobs-1 = aantal cores/multithreading\n",
    "# # verbose print spul\n",
    "# clf = GridSearchCV(pipeline, parameter_grid, verbose=1, n_jobs=-1, cv = 5)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print clf.best_params_\n",
    "# print clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 1, 'gamma': 0}\n",
      "0.963541666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.4s finished\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

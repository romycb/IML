{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "In this notebook we will try out different classifiers. We will be using different versions of feature analysis to show which one is the best. Lastly we will compare the scores and the classifier with the highest scores will be used for the widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleCV import *\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "We are using cross validation to lower the change of overfitting. We are using it in two ways. \n",
    "\n",
    "The datasets that the classifiers use has been split up. This is done below. We make a training set which has 80% of the data in it. We also make a test set with 20% of the data in it. A classifier will train with the training set, and to test if it trained wel the test set can be used. \n",
    "\n",
    "Another way that we are using cross validation is with k-fold. This splits your data randomly into an x amount of folds. One fold will serve as a validation set and the others as a training set. This method is used in the parameter tuning. GridSearch uses this by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "We are using cross validation to lower the change of overfitting. We are using it in two ways. \n",
    "\n",
    "The datasets that the classifiers use has been split up. This is done below. We make a training set which has 80% of the data in it. We also make a test set with 20% of the data in it. A classifier will train with the training set, and to test if it trained wel the test set can be used. \n",
    "\n",
    "Another way that we are using cross validation is with k-fold. This splits your data randomly into an x amount of folds. One fold will serve as a validation set and the others as a training set. This method is used in the parameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_angle</th>\n",
       "      <th>blob_area</th>\n",
       "      <th>blob_centroid_x</th>\n",
       "      <th>blob_centroid_y</th>\n",
       "      <th>blob_width</th>\n",
       "      <th>centroid_bottom_is_empty</th>\n",
       "      <th>centroid_is_empty</th>\n",
       "      <th>centroid_top_is_empty</th>\n",
       "      <th>grid_2_0</th>\n",
       "      <th>grid_2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>grid_5_0</th>\n",
       "      <th>grid_5_1</th>\n",
       "      <th>grid_5_2</th>\n",
       "      <th>grid_5_3</th>\n",
       "      <th>grid_5_4</th>\n",
       "      <th>grid_5_5</th>\n",
       "      <th>grid_5_6</th>\n",
       "      <th>grid_5_7</th>\n",
       "      <th>number_of_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.386221</td>\n",
       "      <td>0.469217</td>\n",
       "      <td>0.467661</td>\n",
       "      <td>0.522865</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.295312</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.393815</td>\n",
       "      <td>0.665495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379785</td>\n",
       "      <td>0.533919</td>\n",
       "      <td>0.516829</td>\n",
       "      <td>0.510319</td>\n",
       "      <td>0.586458</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.591960</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.368169</td>\n",
       "      <td>0.187824</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.101772</td>\n",
       "      <td>0.476765</td>\n",
       "      <td>0.456302</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>0.342701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383374</td>\n",
       "      <td>0.376778</td>\n",
       "      <td>0.400050</td>\n",
       "      <td>0.382840</td>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>0.403487</td>\n",
       "      <td>0.287165</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.863493</td>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>0.344453</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.973220</td>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.459344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481894</td>\n",
       "      <td>0.552328</td>\n",
       "      <td>0.562653</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        blob_angle    blob_area  blob_centroid_x  blob_centroid_y  \\\n",
       "count  1920.000000  1920.000000      1920.000000      1920.000000   \n",
       "mean      0.779948     0.386221         0.469217         0.467661   \n",
       "std       0.368169     0.187824         0.139196         0.182193   \n",
       "min       0.000000     0.000000         0.000000         0.000000   \n",
       "25%       0.863493     0.253482         0.378048         0.344453   \n",
       "50%       0.973220     0.341226         0.462067         0.459344   \n",
       "75%       1.000000     0.481894         0.552328         0.562653   \n",
       "max       1.000000     1.000000         1.000000         1.000000   \n",
       "\n",
       "        blob_width  centroid_bottom_is_empty  centroid_is_empty  \\\n",
       "count  1920.000000               1920.000000        1920.000000   \n",
       "mean      0.522865                  0.348958           0.295312   \n",
       "std       0.101772                  0.476765           0.456302   \n",
       "min       0.000000                  0.000000           0.000000   \n",
       "25%       0.500000                  0.000000           0.000000   \n",
       "50%       0.500000                  0.000000           0.000000   \n",
       "75%       0.600000                  1.000000           1.000000   \n",
       "max       1.000000                  1.000000           1.000000   \n",
       "\n",
       "       centroid_top_is_empty     grid_2_0     grid_2_1     ...       \\\n",
       "count            1920.000000  1920.000000  1920.000000     ...        \n",
       "mean                0.211458     0.393815     0.665495     ...        \n",
       "std                 0.408449     0.333569     0.342701     ...        \n",
       "min                 0.000000     0.000000     0.000000     ...        \n",
       "25%                 0.000000     0.062500     0.437500     ...        \n",
       "50%                 0.000000     0.375000     0.812500     ...        \n",
       "75%                 0.000000     0.687500     1.000000     ...        \n",
       "max                 1.000000     1.000000     1.000000     ...        \n",
       "\n",
       "          grid_5_0     grid_5_1     grid_5_2     grid_5_3     grid_5_4  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.379785     0.533919     0.516829     0.510319     0.586458   \n",
       "std       0.383374     0.376778     0.400050     0.382840     0.370961   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.125000     0.000000     0.125000     0.250000   \n",
       "50%       0.250000     0.562500     0.562500     0.500000     0.687500   \n",
       "75%       0.750000     0.937500     0.937500     0.875000     0.937500   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          grid_5_5     grid_5_6     grid_5_7  number_of_holes        label  \n",
       "count  1920.000000  1920.000000  1920.000000      1920.000000  1920.000000  \n",
       "mean      0.551400     0.591960     0.472656         0.188542     4.532813  \n",
       "std       0.369417     0.375565     0.403487         0.287165     2.868122  \n",
       "min       0.000000     0.000000     0.000000         0.000000     0.000000  \n",
       "25%       0.187500     0.250000     0.000000         0.000000     2.000000  \n",
       "50%       0.625000     0.750000     0.437500         0.000000     5.000000  \n",
       "75%       0.875000     0.937500     0.875000         0.500000     7.000000  \n",
       "max       1.000000     1.000000     1.000000         1.000000     9.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Cross validation\n",
    "We are using cross validation to lower the change of overfitting. We are using it in two ways. \n",
    "\n",
    "The datasets that the classifiers use has been split up. This is done below. We make a training set which has 80% of the data in it. We also make a test set with 20% of the data in it. A classifier will train with the training set, and to test if it trained wel the test set can be used. \n",
    "\n",
    "Another way that we are using cross validation is with k-fold. This splits your data randomly into an x amount of folds. One fold will serve as a validation set and the others as a training set. This method is used in the parameter tuning. df = pd.read_csv(\"../dataset-numpy/dataset_analysis_normalized_v3.csv\")\n",
    "df.head()\n",
    "\n",
    "# split df in data (X) and labels (y)\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# create train and test data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20, random_state=67)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "PCA stands for pricipal components analysis. With PCA the dimensions of data is reduced, it is summarized. In our case we took 0.95 procent of the components. When testing our classifiers with the PSA dataset some classifiers decreased in score and some increased. We made the choice to only use the PCA datasets on the classifiers where the score increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "We chose two naive bays models. Gaussian which can be used if a dataset has a normal distribution. Bernoulli which works better if the features are with zeros and ones. The outputs of these classifiers where rather low it would not reach the level of other classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian : 0.94270833333333337\n",
    "Gaussian worked better with the PCA dataset. For this classifier the most confusion was around number there was a lot of confusion placing the number 9 with the correct label, the classifier misplaced it 7 times. As a 2,3,4 and for a 8 and 9.  The number 9 was confused 9 times. As a 4,5 and 8. The numbers 5 and 6 where the only number that are not confused.\n",
    "\n",
    "Number 1 -> 2\n",
    "Number 2 -> 1\n",
    "Number 3 -> 1\n",
    "Number 4 -> 1\n",
    "Number 4(4) -> 9\n",
    "Number 5(4) -> 9\n",
    "Number 7 -> 4\n",
    "Number 8 -> 1,9\n",
    "Number 9 -> 1,3,7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942708333333\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  1  1  1  0  0  0  2  2]\n",
      " [ 0  2 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 24  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 25  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 32  1]\n",
      " [ 0  0  0  0  4  4  0  0  1 48]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        42\n",
      "          1       0.95      0.84      0.89        44\n",
      "          2       0.97      0.94      0.96        35\n",
      "          3       0.97      0.97      0.97        40\n",
      "          4       0.83      0.96      0.89        25\n",
      "          5       0.86      1.00      0.93        25\n",
      "          6       1.00      1.00      1.00        32\n",
      "          7       0.98      0.98      0.98        51\n",
      "          8       0.91      0.97      0.94        33\n",
      "          9       0.91      0.84      0.87        57\n",
      "\n",
      "avg / total       0.94      0.94      0.94       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Gaussian\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_pca, y_train)\n",
    "#print \"Gaussian :\",gnb.score(X_test_pca, y_test)\n",
    "prediction=gnb.predict(X_test_pca)\n",
    "accuracy_score_gnb = metrics.accuracy_score(prediction,y_test)\n",
    "\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_gnb \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)\n",
    "print metrics.classification_report(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli: 0.84895833333333337\n",
    "We also tried to use the Bernoulli classifier. This classifier scored rather low. This is because our dataset does not only consist out of zeros and ones but also out of other numbers. When looking at the confusion matrix every number has been confused for other numbers except 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Bernoulli:', 0.86979166666666663)\n",
      "[[42  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 30  0  1  6  0  1  0  0  2]\n",
      " [ 0  4 30  2  0  0  0  0  0  0]\n",
      " [ 0  0  0 32  0  0  0  0  1  1]\n",
      " [ 0  1  0  0 22  0  0  2  0  4]\n",
      " [ 0  1  1  2  0 23  0  0  1  0]\n",
      " [ 0  0  1  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 49  1  1]\n",
      " [ 0  3  1  1  0  1  0  0 32  2]\n",
      " [ 0  0  1  2  0  4  0  0  0 43]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Bernoulli\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "#print \"Bernoulli:\",bnb.score(X_test, y_test)\n",
    "prediction=bnb.predict(X_test)\n",
    "accuracy_score_bnb = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_bnb\n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRF = RandomForestClassifier()\n",
    "clfRF.fit(X_train, y_train)\n",
    "prediction=clfRF.predict(X_test)\n",
    "\n",
    "accuracy_score_rf = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_rf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomize search\n",
    "When running random forest with default settings the score was about 0.945. The descision was made to tune the hyper parameters. To get the best possible parameters we used the randomized search in combination with the grid search. This tries all the combinations between a certain range. When using the randomized search we used k-fold cross validation, this helps with overfitting. It this case the k-fold is 5 (cv=5). This means it will randomly split the dataset into 5 folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trees \n",
    "n_estimators=[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] \n",
    "\n",
    "#number of features considered for splitting at leaf node\n",
    "max_features =['sqrt', 'auto']\n",
    "\n",
    "#method for sampling data points (with or without replacement)\n",
    "bootstrap=[True, False]\n",
    "\n",
    "#min number of data points allowed in a leaf node\n",
    "min_samples_leaf=[1,2,4]\n",
    "\n",
    "#min number of data points placed in a node before the node is split\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "#max number of levels in each decision tree\n",
    "max_depth=[int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "randomgrid = {'n_estimators':n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'bootstrap': bootstrap,\n",
    "             'min_samples_leaf': min_samples_leaf,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'max_depth': max_depth}\n",
    "\n",
    "clfRF = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clfRF, param_distributions = randomgrid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The best params that came out of the randomize search:\n",
    "  bootstrap: False\n",
    "  <br>\n",
    "  max_depth: 20\n",
    "  <br>\n",
    "  max_features: 'sqrt'\n",
    "  <br>\n",
    "  min_samples_leaf: 1\n",
    "  <br>\n",
    "  min_samples_split: 2\n",
    "  <br>\n",
    "  n_estimators: 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "To get even better hyper parameters, we are using the result of the randomize search to narrow down the range for the grid search. Grid search also uses k fold cross validation, in this case it is set to 3 folds. There is a change that this score could be better, but it could also descrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [10,20,30,40,50],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'n_estimators': [1400,1500,1600,1800,1900,2000]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "clfRF = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = clfRF, param_grid = parameters, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The best params that came out of the grid search\n",
    "bootstrap: False\n",
    "<br>\n",
    "max_depth: 40\n",
    "<br>\n",
    "max_features: 'sqrt'\n",
    "<br>\n",
    "min_samples_leaf: 1\n",
    "<br>\n",
    "min_samples_split: 2\n",
    "<br>\n",
    "n_estimators: 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default setting of the random forest the acurracy score was about 0.945. Running the random forest with the tuned parameters the accurracy score came to 0.9765625. To be sure we also ran the params that came out of the randomize search. This was an accurracy score of 0.979166666667, which is higher than the grid search. \n",
    "This is an increase of about 3%. \n",
    "\n",
    "When looking at the confusion matrix number 1 catches our attention. Number 1 was mismatched to a 2, 8 and 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest with parameters from random and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.979166666667\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  1  0  0  0  0  0  2  1]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 29  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 51  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 32  0]\n",
      " [ 0  0  0  1  0  0  0  0  0 50]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        42\n",
      "          1       1.00      0.91      0.95        43\n",
      "          2       0.97      1.00      0.99        33\n",
      "          3       0.97      1.00      0.99        39\n",
      "          4       1.00      0.94      0.97        31\n",
      "          5       1.00      1.00      1.00        29\n",
      "          6       1.00      0.97      0.98        33\n",
      "          7       1.00      1.00      1.00        51\n",
      "          8       0.91      1.00      0.96        32\n",
      "          9       0.94      0.98      0.96        51\n",
      "\n",
      "avg / total       0.98      0.98      0.98       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(bootstrap= False,  max_depth= 20, max_features= 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 1800)\n",
    "clfRF.fit(X_train, y_train)\n",
    "prediction=clfRF.predict(X_test)\n",
    "\n",
    "accuracy_score_rf = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy :\",accuracy_score_rf \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test) \n",
    "print metrics.classification_report(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree\n",
    "The decision tree scored with default settings only  0.86979166666666663. Tuning parameters will not get this classifier to the accurracy scores of other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.875)\n",
      "[[34  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 37  8  1  3  0  1  0  2  1]\n",
      " [ 0  1 32  2  0  1  0  0  0  1]\n",
      " [ 1  0  1 33  1  2  0  0  0  0]\n",
      " [ 0  1  1  0 41  0  0  0  2  2]\n",
      " [ 0  0  1  0  0 25  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 36  0  2  0]\n",
      " [ 0  0  0  2  0  0  0 37  0  2]\n",
      " [ 0  1  0  1  1  0  1  0 32  1]\n",
      " [ 0  0  0  0  0  0  0  2  0 29]]\n"
     ]
    }
   ],
   "source": [
    "clfDT = DecisionTreeClassifier()\n",
    "clfDT.fit(X_train, y_train) \n",
    "prediction=clfDT.predict(X_test)\n",
    "\n",
    "accuracy_score_dt = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",accuracy_score_dt)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfKNN = KNeighborsClassifier()\n",
    "# Train the classifier with the training data and training labels\n",
    "clfKNN.fit(X_train, y_train)\n",
    "    # Score the classifier\n",
    "    # (calculates the mean accuracy of the given test data) \n",
    "prediction=clfKNN.predict(X_test)\n",
    "print \"Accuracy: \", metrics.accuracy_score(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the KNN we first let it run with default settings. The accurracy score was already near the 0.97135416666666663 . So we decided to try to make this higher with tuning the hyper parameters. We first ran the classifier with an iteration. Where it would try the neighbors 1-9 in the params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    # Create a classifier with k \n",
    "    clfKNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    # Train the classifier with the training data and training labels\n",
    "    clfKNN.fit(X_train, y_train)\n",
    "    # Score the classifier\n",
    "    # (calculates the mean accuracy of the given test data) \n",
    "    prediction=clfKNN.predict(X_test)\n",
    "    print \"Accuracy: \", i ,metrics.accuracy_score(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN with neighbor iteration\n",
    "Accuracy: 0.96354166666666663 Neighbors: 1\n",
    "<br>\n",
    "Accuracy: 0.96354166666666663 Neighbors: 2\n",
    "<br>\n",
    "Accuracy: 0.97135416666666663 Neighbors: 3\n",
    "<br>\n",
    "Accuracy: 0.96875........................ Neighbors: 4\n",
    "<br>\n",
    "Accuracy: 0.97135416666666663 Neighbors: 5\n",
    "<br>\n",
    "Accuracy: 0.96614583333333337 Neighbors: 6\n",
    "<br>\n",
    "Accuracy: 0.96354166666666663 Neighbors: 7\n",
    "<br>\n",
    "Accuracy: 0.96614583333333337 Neighbors: 8\n",
    "<br>\n",
    "Accuracy: 0.96614583333333337 Neighbors: 9\n",
    "<br>\n",
    "<br>\n",
    "The highest accurracy score of running the classifier with an iterator is the same as when running it default 0.97135416666666663. As the iteration only focuced on the neighbors we decided to use grid search. We now tuned more than one parameter.\n",
    "<br>\n",
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the instance\n",
    "clfKNN = KNeighborsClassifier(n_jobs=-1)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "clfKNN1 = GridSearchCV(clfKNN, param_grid=params, n_jobs=-1, verbose=1)\n",
    "#Learning\n",
    "clfKNN1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best params for KNN with grid search\n",
    "algorithm': 'auto'\n",
    "<br>\n",
    "leaf_size': 1\n",
    "<br>\n",
    "n_jobs': -1\n",
    "<br>\n",
    "n_neighbors': 6\n",
    "<br>\n",
    "weights': 'distance'\n",
    "<br>\n",
    "<br>\n",
    "Running the classifier with the params from the gridsearch improved the accurracy score. It is now 0.97395833333333337. It is an improvement of about 0.20%. When looking at the confusion matrix number 1 stands out. Number 1 is misplaced for numbers 2,3,4,8 and 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.97395833333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  1  1  1  0  0  0  1  1]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 27  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 51  0  1]\n",
      " [ 0  0  0  0  1  0  0  0 34  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "clfKNN = KNeighborsClassifier(n_neighbors = 6, n_jobs = -1, weights= 'distance', leaf_size= 1, algorithm= 'auto')\n",
    "clfKNN.fit(X_train, y_train)\n",
    "prediction=clfKNN.predict(X_test)\n",
    "\n",
    "accuracy_score_knn = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_knn \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD\n",
    "The accurracy score when running SGD with default settings is 0.9375. With changing the params manually we came to a score of 0.958333333333. When looking at the confusion matrix number 1 gets confused for a 2,4,8 and 9. Also number 2 get confused for number 1 and number 4 gets confused for a 1 and 9.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958333333333\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  1  0  1  0  0  0  3  2]\n",
      " [ 0  2 33  0  0  1  0  1  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  2  0  0 28  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 28  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 31  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 49]]\n"
     ]
    }
   ],
   "source": [
    "clfSGD = linear_model.SGDClassifier(loss = 'log', n_iter =1000)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "prediction=clfSGD.predict(X_test)\n",
    "\n",
    "accuracy_score_sgd = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_sgd \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default SVM with Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979166666667\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Nu-Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942708333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "clf = NuSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Linear Support Vector Classifiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973958333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()m\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these three types of support vector machines, the __SVC__ scores the highest. We will use this one and tweak the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Gridsearch\n",
    "\n",
    "Using grid search we can find which parameters are the best to get the highest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:   52.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 1.7000000000000006, 'gamma': 0.20000000000000004}\n",
      "0.981770833333\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(1, 2, 0.1), \n",
    "              'gamma': np.arange(.1, .5, 0.05)}\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(), parameters, verbose=1, n_jobs=-1, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print clf.best_params_\n",
    "print clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9796875\n",
      "0.966145833333\n",
      "0.9921875\n"
     ]
    }
   ],
   "source": [
    "scores = np.zeros((100))\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20)\n",
    "    clf = svm.SVC(kernel =\"rbf\", C=1.2, gamma=0.3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores[i] = clf.score(X_test, y_test)\n",
    "\n",
    "print 'mean', scores.mean()\n",
    "\n",
    "print 'min', scores.min()\n",
    "print 'max', scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best params for SVM with grid search\n",
    "kernel': 'rbf'\n",
    "<br>\n",
    "C': 1.2\n",
    "<br>\n",
    "gamma': 0.171\n",
    "\n",
    "This scores 0.979 on average when we run it with these parameters a 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.978619791667\n",
      "min 0.9609375\n",
      "max 0.9921875\n"
     ]
    }
   ],
   "source": [
    "scores = np.zeros((100))\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20)\n",
    "    pca = PCA(0.95)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    clf = svm.SVC(kernel =\"rbf\", C=1.2, gamma=0.3)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    scores[i] = clf.score(X_test_pca, y_test)\n",
    "\n",
    "print 'mean', scores.mean()\n",
    "\n",
    "print 'min', scores.min()\n",
    "print 'max', scores.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scores 0.979 on average when we run it with these parameters a 100 times. It scores the same as without PCA, so we decided to leave it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Classifier SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel =\"rbf\", C=1.2, gamma=0.3)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 35  0  0  0  1  0  0]\n",
      " [ 0  0  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 37  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 46  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 37  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 33  0]\n",
      " [ 0  0  0  0  0  0  0  1  0 33]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        38\n",
      "          1       0.93      1.00      0.96        39\n",
      "          2       1.00      0.98      0.99        43\n",
      "          3       1.00      0.97      0.99        36\n",
      "          4       1.00      1.00      1.00        39\n",
      "          5       1.00      1.00      1.00        37\n",
      "          6       1.00      1.00      1.00        46\n",
      "          7       0.95      1.00      0.97        37\n",
      "          8       1.00      0.94      0.97        35\n",
      "          9       1.00      0.97      0.99        34\n",
      "\n",
      "avg / total       0.99      0.99      0.99       384\n",
      "\n",
      "accuracy:  0.986979166667\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "print confusion_matrix (labels, predictions)\n",
    "print classification_report(labels, predictions)\n",
    "print 'accuracy: ', metrics.accuracy_score(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested svm on different datasets to see which would score the best\n",
    "\n",
    "- __dataset_analysis_normalized_v3.csv - the latest normalized version__ <br>\n",
    "0.979505208333\n",
    "- dataset_analysis_v3.csv - the latest version not normalized <br>\n",
    "0.090546875\n",
    "- dataset_analysis_normalized_with_contours.csv - normalized version without the column 'blob_amount_contours'  <br>\n",
    "0.979479166667\n",
    "- dataset_analysis_with_contours.csv - not normalized version without the column 'blob_amount_contours'  <br>\n",
    "0.0909635416667\n",
    "\n",
    "The not normalized versions scored the worst. These are not useful at all. The version without 'blob_amount_contours' lowers the score a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 41  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 36  0  2  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 37  0  0  0  0]\n",
      " [ 0  0  0  0  0  1 37  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 38  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 37  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 48]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        34\n",
      "          1       0.95      1.00      0.98        41\n",
      "          2       1.00      1.00      1.00        41\n",
      "          3       0.97      0.95      0.96        38\n",
      "          4       1.00      0.97      0.98        29\n",
      "          5       0.93      1.00      0.96        37\n",
      "          6       0.97      0.97      0.97        38\n",
      "          7       1.00      0.97      0.99        39\n",
      "          8       1.00      0.95      0.97        39\n",
      "          9       0.98      1.00      0.99        48\n",
      "\n",
      "avg / total       0.98      0.98      0.98       384\n",
      "\n",
      "0.979166666667\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "print confusion_matrix (labels, predictions)\n",
    "print classification_report(labels, predictions)\n",
    "print metrics.accuracy_score(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "When running LG with default settings a score around 0.9583 comes out. We decided to tune the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.9765625)\n",
      "[[32  0  0  0  0  0  0  0  0  1]\n",
      " [ 0 39  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 38  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 33  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 41  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 33  0  0  1  0]\n",
      " [ 0  0  0  0  1  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 41  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 39  1]\n",
      " [ 0  0  0  1  0  0  0  0  0 35]]\n"
     ]
    }
   ],
   "source": [
    "clfLG = LogisticRegression()\n",
    "clfLG.fit(X_train, y_train)\n",
    "prediction=clfLG.predict(X_test)\n",
    "accuracy_score_lg = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",accuracy_score_lg \n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "parameters = {'logreg__C':np.arange(0.01,100,10)}\n",
    "clfLG = GridSearchCV(pipeline,parameters,cv=5, n_jobs=-1, verbose =2)\n",
    "clfLG.fit(X_train, y_train)\n",
    "print(\"Best parameters:\\n\",clfLG.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Best params gridsearch\n",
    "logreg__C: 10.01\n",
    "<br>\n",
    "<br>\n",
    "When testing the LG classifier with this param the results went down to about 0.9557. So the best option for LG is to use the default settings. When looking at the matrix of the default settings number 1 stands out. It is confused for a 2, 4, 8 and 9. Number 4 stands out as well and is confused with a 1 and 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Best params gridsearch\n",
    "logreg__C: 10.01\n",
    "<br>\n",
    "<br>\n",
    "When testing the LG classifier with this param the results went down to about 0.9557. So the best option for LG is to use the default settings. When looking at the matrix of the default settings number 1 stands out. It is confused for a 2, 4, 8 and 9. Number 4 stands out as well and is confused with a 1 and 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.955729166667\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  1  0  1  0  0  0  3  2]\n",
      " [ 0  1 33  0  0  1  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  3  0  0 28  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 49  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 32  1]\n",
      " [ 0  0  0  0  0  0  0  2  0 48]]\n"
     ]
    }
   ],
   "source": [
    "clfLG = LogisticRegression(random_state=0, solver='lbfgs',  multi_class='multinomial', C =10.01 )\n",
    "clfLG.fit(X_train, y_train)\n",
    "prediction=clfLG.predict(X_test)\n",
    "#evaluation(Accuracy)\n",
    "print \"Accuracy:\",metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Confusion Metrix)\n",
    "print metrics.confusion_matrix(prediction,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gaussian               94.270833\n",
       "Bernoulli              84.895833\n",
       "Random Forest          97.656250\n",
       "Decision Tree          86.979167\n",
       "KNN                    97.395833\n",
       "SGD                    95.833333\n",
       "SVM                    98.096354\n",
       "Logestic Regression    95.572917\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_svm = scores.mean()\n",
    "dfResults = pd.Series([accuracy_score_gnb*100, accuracy_score_bnb*100,accuracy_score_rf*100, accuracy_score_dt*100,\n",
    "                       accuracy_score_knn*100, accuracy_score_sgd*100, accuracy_score_svm*100, accuracy_score_lg*100],\n",
    "                      index=['Gaussian', 'Bernoulli', 'Random Forest', 'Decision Tree',\n",
    "                             'KNN', 'SGD','SVM', 'Logistic Regression'])\n",
    "dfResults.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meer grid based dingen toevoegen, nu gaan we niet hoger komen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleCV import *\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import sklearn \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# – Which steps did you take and which alternatives?\n",
    "# – What were the results of each of these steps and what was the\n",
    "# best option\n",
    "# – Which algorithm performs best with which hyperparameters\n",
    "# – Which labels get confused (confusion matrix)?\n",
    "# – What was your cross-validation strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_angle</th>\n",
       "      <th>blob_area</th>\n",
       "      <th>blob_centroid_x</th>\n",
       "      <th>blob_centroid_y</th>\n",
       "      <th>blob_width</th>\n",
       "      <th>centroid_bottom_is_empty</th>\n",
       "      <th>centroid_is_empty</th>\n",
       "      <th>centroid_top_is_empty</th>\n",
       "      <th>grid_2_0</th>\n",
       "      <th>grid_2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>grid_5_0</th>\n",
       "      <th>grid_5_1</th>\n",
       "      <th>grid_5_2</th>\n",
       "      <th>grid_5_3</th>\n",
       "      <th>grid_5_4</th>\n",
       "      <th>grid_5_5</th>\n",
       "      <th>grid_5_6</th>\n",
       "      <th>grid_5_7</th>\n",
       "      <th>number_of_holes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.386221</td>\n",
       "      <td>0.469217</td>\n",
       "      <td>0.467661</td>\n",
       "      <td>0.522865</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.295312</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.393815</td>\n",
       "      <td>0.665495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379785</td>\n",
       "      <td>0.533919</td>\n",
       "      <td>0.516829</td>\n",
       "      <td>0.510319</td>\n",
       "      <td>0.586458</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.591960</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>4.532813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.368169</td>\n",
       "      <td>0.187824</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.101772</td>\n",
       "      <td>0.476765</td>\n",
       "      <td>0.456302</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.333569</td>\n",
       "      <td>0.342701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383374</td>\n",
       "      <td>0.376778</td>\n",
       "      <td>0.400050</td>\n",
       "      <td>0.382840</td>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>0.375565</td>\n",
       "      <td>0.403487</td>\n",
       "      <td>0.287165</td>\n",
       "      <td>2.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.863493</td>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>0.344453</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.973220</td>\n",
       "      <td>0.341226</td>\n",
       "      <td>0.462067</td>\n",
       "      <td>0.459344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481894</td>\n",
       "      <td>0.552328</td>\n",
       "      <td>0.562653</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        blob_angle    blob_area  blob_centroid_x  blob_centroid_y  \\\n",
       "count  1920.000000  1920.000000      1920.000000      1920.000000   \n",
       "mean      0.779948     0.386221         0.469217         0.467661   \n",
       "std       0.368169     0.187824         0.139196         0.182193   \n",
       "min       0.000000     0.000000         0.000000         0.000000   \n",
       "25%       0.863493     0.253482         0.378048         0.344453   \n",
       "50%       0.973220     0.341226         0.462067         0.459344   \n",
       "75%       1.000000     0.481894         0.552328         0.562653   \n",
       "max       1.000000     1.000000         1.000000         1.000000   \n",
       "\n",
       "        blob_width  centroid_bottom_is_empty  centroid_is_empty  \\\n",
       "count  1920.000000               1920.000000        1920.000000   \n",
       "mean      0.522865                  0.348958           0.295312   \n",
       "std       0.101772                  0.476765           0.456302   \n",
       "min       0.000000                  0.000000           0.000000   \n",
       "25%       0.500000                  0.000000           0.000000   \n",
       "50%       0.500000                  0.000000           0.000000   \n",
       "75%       0.600000                  1.000000           1.000000   \n",
       "max       1.000000                  1.000000           1.000000   \n",
       "\n",
       "       centroid_top_is_empty     grid_2_0     grid_2_1     ...       \\\n",
       "count            1920.000000  1920.000000  1920.000000     ...        \n",
       "mean                0.211458     0.393815     0.665495     ...        \n",
       "std                 0.408449     0.333569     0.342701     ...        \n",
       "min                 0.000000     0.000000     0.000000     ...        \n",
       "25%                 0.000000     0.062500     0.437500     ...        \n",
       "50%                 0.000000     0.375000     0.812500     ...        \n",
       "75%                 0.000000     0.687500     1.000000     ...        \n",
       "max                 1.000000     1.000000     1.000000     ...        \n",
       "\n",
       "          grid_5_0     grid_5_1     grid_5_2     grid_5_3     grid_5_4  \\\n",
       "count  1920.000000  1920.000000  1920.000000  1920.000000  1920.000000   \n",
       "mean      0.379785     0.533919     0.516829     0.510319     0.586458   \n",
       "std       0.383374     0.376778     0.400050     0.382840     0.370961   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.125000     0.000000     0.125000     0.250000   \n",
       "50%       0.250000     0.562500     0.562500     0.500000     0.687500   \n",
       "75%       0.750000     0.937500     0.937500     0.875000     0.937500   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          grid_5_5     grid_5_6     grid_5_7  number_of_holes        label  \n",
       "count  1920.000000  1920.000000  1920.000000      1920.000000  1920.000000  \n",
       "mean      0.551400     0.591960     0.472656         0.188542     4.532813  \n",
       "std       0.369417     0.375565     0.403487         0.287165     2.868122  \n",
       "min       0.000000     0.000000     0.000000         0.000000     0.000000  \n",
       "25%       0.187500     0.250000     0.000000         0.000000     2.000000  \n",
       "50%       0.625000     0.750000     0.437500         0.000000     5.000000  \n",
       "75%       0.875000     0.937500     0.875000         0.500000     7.000000  \n",
       "max       1.000000     1.000000     1.000000         1.000000     9.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"../dataset-numpy/dataset_analysis.csv\")\n",
    "# wordt niet hoger door normalizen\n",
    "df = pd.read_csv(\"../dataset-numpy/dataset_analysis_normalized_v3.csv\")\n",
    "df.head()\n",
    "\n",
    "# split df in data (X) and labels (y)\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# create train and test data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20, random_state=67)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "PCA stands for pricipal components analysis. With PCA the dimensions of data is reduced, it is summarized. In our case we took 0.95 procent of the components. When testing our classifiers with the PSA dataset some classifiers decreased in score and some increased. We made the choice to only use de PSA datasets where the score increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "We chose two naive bays models. Gaussian which can be used if a dataset has a normal distribution. Bernoulli which works better if the features are with zeros and ones. The outputs of these classifiers where rather low it would not reach the level of other classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian : 0.94270833333333337\n",
    "Gaussian worked better with the PCA dataset. For this classifier there was a lot of confusion placing the number 1 with the correct label, the classifier misplaced it 7 times. As a 2,3,4 and for a 8 and 9.  The number 9 was confused 9 times. As a 4,5 and 8. The numbers 5 and 6 where the only number that are not confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.94270833333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 37  1  1  1  0  0  0  2  2]\n",
      " [ 0  2 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 24  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 25  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 32  1]\n",
      " [ 0  0  0  0  4  4  0  0  1 48]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.270833333333343"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes Gaussian\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_pca, y_train)\n",
    "#print \"Gaussian :\",gnb.score(X_test_pca, y_test)\n",
    "prediction=gnb.predict(X_test_pca)\n",
    "accuracy_score_gnb = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_gnb)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli: 0.84895833333333337\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.84895833333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 32  1  1  3  0  0  1  3  2]\n",
      " [ 0  6 26  1  0  0  0  0  0  0]\n",
      " [ 0  0  1 34  0  3  0  0  0  4]\n",
      " [ 0  1  0  0 22  0  0  1  0  4]\n",
      " [ 0  0  1  1  0 19  0  0  0  0]\n",
      " [ 0  0  1  0  1  0 32  0  1  0]\n",
      " [ 0  0  0  0  3  0  0 49  0  2]\n",
      " [ 0  0  0  0  0  0  0  0 31  2]\n",
      " [ 0  0  4  3  0  7  0  0  0 39]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Bernoulli\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "#print \"Bernoulli:\",bnb.score(X_test, y_test)\n",
    "prediction=bnb.predict(X_test)\n",
    "accuracy_score_bnb = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_bnb)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest randomize search\n",
    "When running random forest with default settings the score was rather high. The descision was made to tune the hyper parameters. To get the best possible parameters we used the randomized search in combination with the grid search. This tries all the combinations between a certain range. The best params that came out of the randomize seach are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of trees \n",
    "n_estimators=[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] \n",
    "\n",
    "#number of features considered for splitting at leaf node\n",
    "max_features =['sqrt', 'auto']\n",
    "\n",
    "#method for sampling data points (with or without replacement)\n",
    "bootstrap=[True, False]\n",
    "\n",
    "#min number of data points allowed in a leaf node\n",
    "min_samples_leaf=[1,2,4]\n",
    "\n",
    "#min number of data points placed in a node before the node is split\n",
    "min_samples_split=[2,5,10]\n",
    "\n",
    "#max number of levels in each decision tree\n",
    "max_depth=[int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "randomgrid = {'n_estimators':n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'bootstrap': bootstrap,\n",
    "             'min_samples_leaf': min_samples_leaf,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'max_depth': max_depth}\n",
    "\n",
    "clfRF = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clfRF, param_distributions = randomgrid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_\n",
    "# {'bootstrap': False,\n",
    "#  'max_depth': 20,\n",
    "#  'max_features': 'sqrt',\n",
    "#  'min_samples_leaf': 1,\n",
    "#  'min_samples_split': 2,\n",
    "#  'n_estimators': 1800}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest Grid search\n",
    "To get even better hyper parameters, we are using the result of the randomize search to narrow down the range for the grid search. There is a change that this score could be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "parameters = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [10,20,30,40,50],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'n_estimators': [1400,1500,1600,1800,1900,2000]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "clfRF = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = clfRF, param_grid = parameters, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "# {'bootstrap': False,\n",
    "#  'max_depth': 40,\n",
    "#  'max_features': 'sqrt',\n",
    "#  'min_samples_leaf': 1,\n",
    "#  'min_samples_split': 2,\n",
    "#  'n_estimators': 1600}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9453125)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 36  1  0  1  0  0  0  3  1]\n",
      " [ 0  2 32  0  1  0  0  1  1  0]\n",
      " [ 0  0  1 40  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 27  0  0  0  1  1]\n",
      " [ 0  0  0  0  0 27  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 50  1  0]\n",
      " [ 0  0  0  0  0  0  0  0 27  1]\n",
      " [ 0  0  0  0  0  1  0  0  1 50]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with default settings \n",
    "clfRF = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "# Train the classifier to take the training features and learn how they relate to the training y\n",
    "clfRF.fit(X_train, y_train)\n",
    "#print \"Random forest:\",clfRF.score(X_test, y_test)\n",
    "prediction=clfRF.predict(X_test)\n",
    "\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))\n",
    "#With PCA\n",
    "#Random forest: 0.9140625\n",
    "#Without\n",
    "#Random forest: 0.9375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest with parameters from random and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.97916666666666663)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  1  0  0  0  0  0  2  1]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 39  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 29  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 51  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 32  0]\n",
      " [ 0  0  0  1  0  0  0  0  0 51]]\n"
     ]
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(bootstrap= False,  max_depth= 40, max_features= 'sqrt', min_samples_leaf = 1, min_samples_split = 2, n_estimators = 1600)\n",
    "clfRF.fit(X_train, y_train)\n",
    "prediction=clfRF.predict(X_test)\n",
    "\n",
    "accuracy_score_rf = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_rf)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))\n",
    "#With PCA\n",
    "#Random forest: 0.9609375\n",
    "#Without\n",
    "#Random forest: 0.97916666666666663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.85416666666666663)\n",
      "[[38  0  0  0  0  0  0  0  2  0]\n",
      " [ 0 35  4  0  2  0  0  1  4  0]\n",
      " [ 2  3 26  0  1  1  0  1  0  0]\n",
      " [ 0  0  3 36  0  2  0  1  1  5]\n",
      " [ 0  0  0  0 25  0  0  0  2  1]\n",
      " [ 0  0  0  2  0 25  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 32  0  2  0]\n",
      " [ 0  0  0  0  0  0  0 46  2  2]\n",
      " [ 0  1  1  1  1  0  0  0 21  0]\n",
      " [ 2  0  0  1  0  1  0  2  1 44]]\n"
     ]
    }
   ],
   "source": [
    "clfDT = DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_features = None, max_depth = 52)\n",
    "clfDT.fit(X_train, y_train) \n",
    "prediction=clfDT.predict(X_test)\n",
    "\n",
    "accuracy_score_dt = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_dt)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))\n",
    "#With PCA\n",
    "#Decision tree: 0.825520833333\n",
    "#Without\n",
    "#Decision tree: 0.854166666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the instance\n",
    "clfKNN = KNeighborsClassifier(n_jobs=-1)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "clfKNN1 = GridSearchCV(clfKNN, param_grid=params, n_jobs=-1, verbose=1)\n",
    "#Learning\n",
    "clfKNN1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 1,\n",
       " 'n_jobs': -1,\n",
       " 'n_neighbors': 6,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfKNN1.best_params_\n",
    "# {'algorithm': 'auto',\n",
    "#  'leaf_size': 1,\n",
    "#  'n_jobs': -1,\n",
    "#  'n_neighbors': 6,\n",
    "#  'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.97395833333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  1  1  1  0  0  0  1  1]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 39  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 27  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 51  0  1]\n",
      " [ 0  0  0  0  1  0  0  0 34  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# niet accurate, hoeveelheid neighbors:\n",
    "# Score KNN:  1 0.971354166667\n",
    "# Score KNN:  2 0.9609375\n",
    "# Score KNN:  3 0.963541666667\n",
    "# Score KNN:  4 0.966145833333\n",
    "# Score KNN:  5 0.963541666667\n",
    "# Score KNN:  6 0.963541666667\n",
    "# Score KNN:  7 0.963541666667\n",
    "# Score KNN:  8 0.9609375\n",
    "# Score KNN:  9 0.963541666667\n",
    "\n",
    "\n",
    "\n",
    "clfKNN = KNeighborsClassifier(n_neighbors = 6, n_jobs = -1, weights= 'distance', leaf_size= 1, algorithm= 'auto')\n",
    "# for i in range (1,10):\n",
    "#     # Create a classifier with k \n",
    "#     clfKNN = KNeighborsClassifier(n_neighbors=i)\n",
    "#     # Train the classifier with the training data and training labels\n",
    "#     clfKNN.fit(X_train, y_train)\n",
    "\n",
    "#     # Score the classifier\n",
    "#     # (calculates the mean accuracy of the given test data) \n",
    "#     score = clfKNN.score(test_set, y_test)\n",
    "#     print \"Score KNN: \", i , score\n",
    "clfKNN.fit(X_train, y_train)\n",
    "\n",
    "prediction=clfKNN.predict(X_test)\n",
    "\n",
    "accuracy_score_knn = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_knn)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))\n",
    "# print \"Score KNN: \", i , score\n",
    "#With PCA\n",
    "# KNN 0.0.96875\n",
    "#Without\n",
    "# KNN 0.97395833333333337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.95833333333333337)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  1  0  1  0  0  0  3  2]\n",
      " [ 0  2 33  0  0  1  0  1  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  2  0  0 28  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 28  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 31  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 49]]\n"
     ]
    }
   ],
   "source": [
    "clfSGD = linear_model.SGDClassifier(loss = 'log', n_iter =1000)\n",
    "clfSGD.fit(X_train, y_train)\n",
    "prediction=clfSGD.predict(X_test)\n",
    "\n",
    "accuracy_score_sgd = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_sgd)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))\n",
    "#Without PCA\n",
    "#0.95833333333333337\n",
    "#With PCA\n",
    "#0.0.95833333333333337\n",
    "\n",
    "#default = 0.934895833333\n",
    "#n_iter =1000 = 0.919270833333\n",
    "#loss = 'log', n_iter =1000 = 0.934895833333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1520 candidates, totalling 7600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 7600 out of 7600 | elapsed: 91.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 1.2000000000000002, 'gamma': 0.156}\n",
      "0.977864583333\n"
     ]
    }
   ],
   "source": [
    "# {'kernel': 'rbf', 'C': 1.9000000000000001, 'gamma': 0.161}\n",
    "# 0.978515625\n",
    "\n",
    "# {'kernel': 'rbf', 'C': 1.9000000000000001, 'gamma': 0.19600000000000001}\n",
    "# 0.977213541667\n",
    "\n",
    "parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(0.1, 2, 0.1), \n",
    "              'gamma': np.arange(.001, .2, 0.005)}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(), parameters, verbose=1, n_jobs=-1, cv = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "print clf.best_params_\n",
    "print clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980963541667\n",
      "0.966145833333\n",
      "0.9921875\n"
     ]
    }
   ],
   "source": [
    "# 0.979166666667 met pca en normalized zonder contours\n",
    "# 0.984375 zonder pca, normalized, zonder contours \n",
    "\n",
    "\n",
    "scores = np.zeros((100))\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20)\n",
    "    clf = svm.SVC(kernel =\"rbf\", C=1.9, gamma=0.161)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores[i] = clf.score(X_test, y_test)\n",
    "\n",
    "print scores.mean()\n",
    "\n",
    "print scores.min()\n",
    "print scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0  0  1  0  1  0  0  0]\n",
      " [ 0 31  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 31  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  2]\n",
      " [ 0  1  0  0  0  0 36  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 42  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 44  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.98        44\n",
      "          1       0.91      1.00      0.95        31\n",
      "          2       1.00      1.00      1.00        33\n",
      "          3       1.00      1.00      1.00        31\n",
      "          4       0.97      0.97      0.97        40\n",
      "          5       1.00      0.95      0.97        41\n",
      "          6       0.97      0.97      0.97        37\n",
      "          7       1.00      1.00      1.00        42\n",
      "          8       1.00      0.98      0.99        45\n",
      "          9       0.95      1.00      0.98        40\n",
      "\n",
      "avg / total       0.98      0.98      0.98       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "print confusion_matrix (labels, predictions)\n",
    "print classification_report(labels, predictions)\n",
    "\n",
    "# for p, l in zip(predictions, labels):\n",
    "#     print p, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98177083333333337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.6s\n",
      "[CV] logreg__C=0.01 ..................................................\n",
      "[CV] ................................... logreg__C=0.01, total=   0.5s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.3s\n",
      "[CV] logreg__C=10.01 .................................................\n",
      "[CV] .................................. logreg__C=10.01, total=   1.4s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.5s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.6s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.6s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.5s\n",
      "[CV] logreg__C=20.01 .................................................\n",
      "[CV] .................................. logreg__C=20.01, total=   1.3s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.4s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.4s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.3s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.4s\n",
      "[CV] logreg__C=30.01 .................................................\n",
      "[CV] .................................. logreg__C=30.01, total=   1.3s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.4s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.4s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.3s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.3s\n",
      "[CV] logreg__C=40.01 .................................................\n",
      "[CV] .................................. logreg__C=40.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=50.01 .................................................\n",
      "[CV] .................................. logreg__C=50.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.4s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=60.01 .................................................\n",
      "[CV] .................................. logreg__C=60.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=70.01 .................................................\n",
      "[CV] .................................. logreg__C=70.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.3s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.4s\n",
      "[CV] logreg__C=80.01 .................................................\n",
      "[CV] .................................. logreg__C=80.01, total=   1.4s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.4s\n",
      "[CV] logreg__C=90.01 .................................................\n",
      "[CV] .................................. logreg__C=90.01, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters:\\n', {'logreg__C': 10.01})\n",
      "('Score:\\n', 0.95768229166666663)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('logreg',LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\"))])\n",
    "parameters = {'logreg__C':np.arange(0.01,100,10)}\n",
    "clfLG = GridSearchCV(pipeline,parameters,cv=5, n_jobs=-1, verbose =2)\n",
    "clfLG.fit(X_train, y_train)\n",
    "print(\"Best parameters:\\n\",clfLG.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy Gaussian:', 0.95572916666666663)\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  1  0  1  0  0  0  3  2]\n",
      " [ 0  1 33  0  0  1  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  3  0  0 28  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 49  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 32  1]\n",
      " [ 0  0  0  0  0  0  0  2  0 48]]\n"
     ]
    }
   ],
   "source": [
    "clfLG = LogisticRegression(random_state=0, solver='lbfgs',  multi_class='multinomial', C =10.01 )\n",
    "clfLG.fit(X_train, y_train)\n",
    "prediction=clfLG.predict(X_test)\n",
    "accuracy_score_lg = metrics.accuracy_score(prediction,y_test)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy Gaussian:\",accuracy_score_lg)\n",
    "#evaluation(Confusion Metrix)\n",
    "print(metrics.confusion_matrix(prediction,y_test))\n",
    "#With PCA\n",
    "#0.94791666666666663\n",
    "#Without\n",
    "#0.95572916666666663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_svm = scores.mean()\n",
    "\n",
    "dfResults = pd.Series([accuracy_score_lg, accuracy_score_svm], index=['a', 'b'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svcModel.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "clf = svm.SVC(kernel= 'rbf', C= 1.9, gamma= 0.161)\n",
    "\n",
    "clf.fit(X, y)\n",
    "# Save the classifier in a file\n",
    "joblib.dump(clf, 'svcModel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1.4000000000000004, 'svm__kernel': 'rbf', 'svm__gamma': 0.20000000000000001}\n",
      "0.977864583333\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # {'pca__n_components': 24, 'svm__C': 2.1, 'svm__kernel': 'rbf', 'svm__gamma': 0.20000000000000004}\n",
    "# # 0.977213541667\n",
    "\n",
    "# pipeline = Pipeline([('pca', PCA()), ('svm', svm.SVC())])\n",
    "# parameter_grid = {\n",
    "# #     'pca__n_components' : range(1,24),\n",
    "#     'svm__kernel' : ['linear', 'rbf'],\n",
    "#     'svm__C' : np.arange(1, 5, 0.1),\n",
    "#     'svm__gamma': np.arange(.1, 1, .1)\n",
    "# }\n",
    "# # parameters = {'kernel' : ('linear', 'rbf'), 'C': np.arange(1,100), 'gamma': np.arange(.1, 1, 0.05)}\n",
    "\n",
    "# # svc = svm.SVC(gamma = j)\n",
    "# # print j\n",
    "# # n_jobs-1 = aantal cores/multithreading\n",
    "# # verbose print spul\n",
    "# clf = GridSearchCV(pipeline, parameter_grid, verbose=1, n_jobs=-1, cv = 5)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print clf.best_params_\n",
    "# print clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    8.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 1, 'gamma': 0}\n",
      "0.963541666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.4s finished\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
